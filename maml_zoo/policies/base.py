

class Policy(object):
    """
    A stateless wrapper, provides functions for executing and updating policy parameters
    The actual parameters are stored in the algo
    """
    def __init__(self, env_spec):
        self._env_spec = env_spec
        self.init_policy = None

    def get_action(self, observation, policy_params):
        """
        Runs a single observation through the specified policy
        Args:
            observation (array) : single observation
            policy_params (params) : 
        Returns:
            (array) : array of arrays of actions for each env
        """
        raise NotImplementedError

    def get_actions(self, observations, policy_params):
        """
        Runs each set of observations through each task specific policy 
        Args:
            observations (array) : array of arrays of observations generated by each task and env
            policy_params (array): array of policy parameters for each task
        Returns:
            (array) : array of arrays of actions for each env
        """
        raise NotImplementedError

    def reset(self, dones=None):
        pass

    @property
    def observation_space(self):
        return self._env_spec.observation_space

    @property
    def action_space(self):
        return self._env_spec.action_space

    @property
    def env_spec(self):
        return self._env_spec

    def log_diagnostics(self, paths):
        """
        Log extra information per iteration based on the collected paths
        """
        pass

    @property
    def state_info_keys(self):
        """
        Return keys for the information related to the policy's state when taking an action.
        :return:
        """
        return [k for k, _ in self.state_info_specs]

    @property
    def state_info_specs(self):
        """
        Return keys and shapes for the information related to the policy's state when taking an action.
        :return:
        """
        return list()

class StochasticPolicy(Policy):

    @property
    def distribution(self):
        """
        :rtype Distribution
        """
        raise NotImplementedError

    def dist_info_sym(self, obs_var, state_info_vars):
        """
        Return the symbolic distribution information about the actions.
        Args:
        	obs_var (placeholder) : symbolic variable for observations
        	state_info_vars (dict) : a dictionary of placeholders that contains information about the 
        	state of the policy at the time it received the observation
        Returns:
        	(dict) : a dictionary of tf placeholders for the policy output distribution
        """
        raise NotImplementedError

    def dist_info(self, obs, state_infos):
        """
        Args:
        	obs_var (placeholder) : symbolic variable for observations
        	state_info_vars (dict) : a dictionary of placeholders that contains information about the 
        	state of the policy at the time it received the observation
        Returns:
        	(dict) : a dictionary of tf placeholders for the policy output distribution
        """
        raise NotImplementedError
